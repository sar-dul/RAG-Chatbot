{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever \n",
    "\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Suppress LangChain deprecation warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress httpx logging\n",
    "logging.getLogger(\"httpx\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Ollama LLM\n",
    "model = ChatOllama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Loading and Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"leave.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Search and bm25 : Hybrid Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "vector_retriever = vector_store.as_retriever(type = \"similarity\", search_kwargs = {\"k\" : 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retriever = BM25Retriever.from_documents(all_splits)\n",
    "bm25_retriever.k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, vector_retriever],weights=[0.4, 0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'leave.pdf', 'page': 2, 'page_label': '3'}, page_content='*Note: The company reserves the right tochange theleavepolicy.Anyremaining/unusedannualleaveand/or sick leave shall be adjustedas leaves takenonSundaysastwo-dayweekendisanaddedfacilityprovidedbyBajraandnotmandatedbylaw.'),\n",
       " Document(id='2e3bc9dc-7cd6-4d3f-84b2-79445c6911e2', metadata={'page': 2, 'page_label': '3', 'source': 'leave.pdf'}, page_content='18.Anemployeemustassurethatatleast75%oftheteammembersarepresentduringaliveproject.Forexample,iftherearefourmembersinateam,atleast¾oftheprojectmembersshouldbeavailable;youmaynottakealeavedayifoneoftheteammembersisalreadyonleave.However,'),\n",
       " Document(id='8a3877b9-8bc7-4a96-9182-4d4da6b08acc', metadata={'page': 1, 'page_label': '2', 'source': 'leave.pdf'}, page_content='FloatingFestiveleaves- 4days(Youcanchoosebetweenanyfestival/publicholidaysyoucelebrate.ThenumberofFloatingleavedependsonthenumberofDashainandTiharholidayssincetheleavesallocatedmaychangeaccordingtotheNepalicalendarforsuchfestivals)'),\n",
       " Document(id='18d009f4-37c5-40bb-aa3d-c8989e0b928d', metadata={'page': 0, 'page_label': '1', 'source': 'leave.pdf'}, page_content='7. Compassionateleave:Anemployeeis entitledtoa maximumof13daysofcompassionateleaveforthelossoftheirimmediatefamilymembers(whichincludesparents,andparents-in-lawformarriedfemaleemployees).'),\n",
       " Document(id='11adba8a-789d-4acf-a4da-8e70b42ec165', metadata={'page': 1, 'page_label': '2', 'source': 'leave.pdf'}, page_content='TheHRdepartmentwillmakethefinaldecisionregardingtheseleaves.Insuchcases,you shouldimmediatelyinformyourteamlead/supervisorof thesituationandprovidevalidreasons.Theteamlead/supervisorshouldanalyzethesituationcarefullyandensure'),\n",
       " Document(metadata={'source': 'leave.pdf', 'page': 2, 'page_label': '3'}, page_content='24.Anyleavethatis unapprovedby theimmediatesupervisorand/ortheHRdepartmentorleavesthatdonotfollowthispolicywillbeconsideredasanunpaidleaveday/sanda warningorfurtherdisciplinaryactionmaybetakenagainsttheemployeedependingonthesituation.'),\n",
       " Document(metadata={'source': 'leave.pdf', 'page': 0, 'page_label': '1'}, page_content='3. Atotalof26workingdays(or208workinghours) inayearisthemaximumleaveanemployeecanearnwhichisequivalentto12daysofsickleaveand14daysofannualleave.\\n4. Annualleave:AnemployeerequestingAnnualleaveforupto3daysneedstoapply5workingdayspriortothedesiredleaveday/s.'),\n",
       " Document(metadata={'source': 'leave.pdf', 'page': 0, 'page_label': '1'}, page_content='IfanemployeehastorequestanAnnualleaveoffourormoredaysinarow,s/hemustinformtheirsupervisorandtheHRdepartmentatleastfourweeksor20workingdaysahead.Thisis becauselongleavesdirectlyimpacttheefficiencyoftheprojectthatanemployeeisinvolvedin.'),\n",
       " Document(metadata={'source': 'leave.pdf', 'page': 0, 'page_label': '1'}, page_content='5. Sickleave:Anemployeecanapplyforsickleaveatanytimebutwouldrequirepromptcommunicationwiththeirsupervisorand/orcoordinationthroughtheHRdepartmentandtheirrespectiveteam.However, ifthesickleaveexceedsthreedays,theemployeeissupposedtohandovera doctor’s')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retriever.get_relevant_documents(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "from pydantic import BaseModel\n",
    "from langchain.schema import BaseRetriever, Document\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Cross-Encoder model\n",
    "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank_docs(query, docs, top_k=10):\n",
    "    # Create query-document pairs for scoring\n",
    "    query_doc_pairs = [(query, doc.page_content) for doc in docs]\n",
    "    \n",
    "    # Get scores from the Cross-Encoder\n",
    "    scores = cross_encoder.predict(query_doc_pairs)\n",
    "    \n",
    "    # Sort documents by their scores in descending order\n",
    "    sorted_docs = [doc for _, doc in sorted(zip(scores, docs), reverse=True)]\n",
    "    \n",
    "    # Return the top-k reranked documents\n",
    "    return sorted_docs[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Cross-Encoder reranking retriever as a Pydantic model\n",
    "class CrossEncoderRerankingRetriever(BaseRetriever, BaseModel):\n",
    "    base_retriever: BaseRetriever\n",
    "    reranker: callable\n",
    "\n",
    "    def get_relevant_documents(self, query: str, *, top_k: int = 10) -> List[Document]:\n",
    "        \n",
    "        #  Retrieve documents using the base retriever\n",
    "        retrieved_docs = self.base_retriever.get_relevant_documents(query, top_k=20)  # Retrieve more docs initially\n",
    "        \n",
    "        # Rerank the retrieved documents using the Cross-Encoder\n",
    "        reranked_docs = self.reranker(query, retrieved_docs, top_k=top_k)\n",
    "        \n",
    "        return reranked_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retriever\n",
    "cross_encoder_retriever = CrossEncoderRerankingRetriever(\n",
    "    base_retriever=ensemble_retriever,\n",
    "    reranker=rerank_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'leave.pdf', 'page': 0, 'page_label': '1'}, page_content='3. Atotalof26workingdays(or208workinghours) inayearisthemaximumleaveanemployeecanearnwhichisequivalentto12daysofsickleaveand14daysofannualleave.\\n4. Annualleave:AnemployeerequestingAnnualleaveforupto3daysneedstoapply5workingdayspriortothedesiredleaveday/s.'),\n",
       " Document(metadata={'source': 'leave.pdf', 'page': 0, 'page_label': '1'}, page_content='IfanemployeehastorequestanAnnualleaveoffourormoredaysinarow,s/hemustinformtheirsupervisorandtheHRdepartmentatleastfourweeksor20workingdaysahead.Thisis becauselongleavesdirectlyimpacttheefficiencyoftheprojectthatanemployeeisinvolvedin.'),\n",
       " Document(id='8a3877b9-8bc7-4a96-9182-4d4da6b08acc', metadata={'page': 1, 'page_label': '2', 'source': 'leave.pdf'}, page_content='FloatingFestiveleaves- 4days(Youcanchoosebetweenanyfestival/publicholidaysyoucelebrate.ThenumberofFloatingleavedependsonthenumberofDashainandTiharholidayssincetheleavesallocatedmaychangeaccordingtotheNepalicalendarforsuchfestivals)')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_encoder_retriever.get_relevant_documents(\"hello\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational RAG (History Aware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    model, ensemble_retriever, contextualize_q_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(model, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today?\n",
      "You: hello\n",
      "Chatbot: Hello! How can I assist you today? Do you have a question about the leave policy at your workplace or would you like to ask something specific related to it?\n",
      "\n",
      "You: what are the types of leave\n",
      "Chatbot: Based on the provided context, here are the types of leave mentioned:\n",
      "\n",
      "1. Annual Leave: up to 3 days in advance need to be applied for\n",
      "2. Sick Leave: equivalent to 12 days\n",
      "3. Compassionate Leave: maximum of 13 days (for loss of immediate family members)\n",
      "4. Floating Festive Leaves: 4 days, can choose between any festival/public holiday celebrated\n",
      "5. Maternity Leave: up to 98 days paid leave during the maternity period\n",
      "6. Paternity Leave: up to 15 paid leaves during the spouse's maternity period\n",
      "\n",
      "You: explain point number 4\n",
      "Chatbot: Point number 4 mentions \"Floating Festive Leaves\". Here's a brief explanation:\n",
      "\n",
      "* Number of Floating Leaves depends on the number of Dashain and Tihar holidays.\n",
      "* The leaves are allocated according to the Nepalicalendar for those festivals.\n",
      "\n",
      "It appears that Floating Festive Leaves are a type of leave that can be taken during specific festival periods, but the exact number of leaves available may vary depending on the length of these holidays.\n",
      "\n",
      "You: my name is sardul and i am a trainee? can i get paid leaves?\n",
      "Chatbot: According to point 17 from the provided context:\n",
      "\n",
      "\"During the trainee period, s/he will not be entitled to any kind of paid leave by the organization apart from observed national, public, or company holidays.\"\n",
      "\n",
      "So, as a trainee, you are not eligible for paid leave during your training period.\n",
      "\n",
      "You: what is my name?\n",
      "Chatbot: Your name is Sardul.\n",
      "\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Assuming conversational_rag_chain is already defined and configured\n",
    "\n",
    "def chatbot_conversation():\n",
    "    session_id = \"abc123\"  # Unique session ID for the conversation\n",
    "    print(\"Chatbot: Hello! How can I assist you today?\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "            break\n",
    "        \n",
    "        # Invoke the conversational RAG chain with the user's input\n",
    "        response = conversational_rag_chain.invoke(\n",
    "            {\"input\": user_input},\n",
    "            config={\"configurable\": {\"session_id\": session_id}},\n",
    "        )[\"answer\"]\n",
    "        \n",
    "        # Display the user's question and the chatbot's response\n",
    "        print(f\"You: {user_input}\")\n",
    "        print(f\"Chatbot: {response}\\n\")\n",
    "\n",
    "# Start the chatbot conversation\n",
    "chatbot_conversation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def generate_leave_comment(reason: str, leave_type: str, start_date: str, end_date: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a structured leave comment based on the provided reason, leave type,\n",
    "    start and end dates.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Validate and parse dates\n",
    "        start = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "        end = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    except ValueError:\n",
    "        return \"Invalid date format. Please use YYYY-MM-DD.\"\n",
    "    \n",
    "    # Calculate the number of leave days\n",
    "    days_requested = (end - start).days + 1\n",
    "\n",
    "    # Generate the leave comment\n",
    "    leave_comment = f\"Leave Type: {leave_type.capitalize()}\\n\" \\\n",
    "                    f\"Leave Dates: {start_date} to {end_date}\\n\" \\\n",
    "                    f\"Reason: {reason}\\n\" \\\n",
    "                    f\"Total Days: {days_requested}\"\n",
    "    \n",
    "    print(leave_comment)\n",
    "    \n",
    "    return leave_comment\n",
    "\n",
    "tools = [generate_leave_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "\n",
    "model = OllamaFunctions(\n",
    "    model=\"llama3.2\", \n",
    "    format=\"json\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = new_model.invoke(\"hello\")\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'generate_leave_comment',\n",
       "  'args': {'reason': 'Sick Leave',\n",
       "   'leave_type': 'Sick Leave',\n",
       "   'start_date': '2022-12-01',\n",
       "   'end_date': '2022-12-05'},\n",
       "  'id': 'call_bd725904cabd40fdb4451831d14ddf5f',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg = new_model.invoke(\"Can you create a leave comment for sick leave from dec 1 22 to dec 5 22?\")\n",
    "msg.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat history in SQLite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    lambda session_id: SQLChatMessageHistory(\n",
    "        session_id=session_id, connection_string=\"sqlite:///sqlite.db\"\n",
    "    ),\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the session ID for the conversation\n",
    "config = {\"configurable\": {\"session_id\": \"session1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello! How can I assist you today? (Type 'exit' to end the conversation)\n",
      "Chatbot: Déjà vu! You're asking me again, and the answer remains the same: I don't know your last name, but you told me your first name is Sardul.\n",
      "Chatbot: Goodbye! Have a great day!\n"
     ]
    }
   ],
   "source": [
    "# Start the chatbot loop\n",
    "print(\"Chatbot: Hello! How can I assist you today? (Type 'exit' to end the conversation)\")\n",
    "\n",
    "while True:\n",
    "    # Get user input\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    # Exit the loop if the user types 'exit' or 'quit'\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Chatbot: Goodbye! Have a great day!\")\n",
    "        break\n",
    "    \n",
    "    # Invoke the conversational RAG chain with the user input\n",
    "    response = conversational_rag_chain.invoke({\"input\": user_input}, config=config)\n",
    "    \n",
    "    # Extract and display the chatbot's response\n",
    "    chatbot_response = response.get(\"answer\", \"I'm sorry, I couldn't generate a response.\")\n",
    "    print(f\"Chatbot: {chatbot_response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
